{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "texts = []\n",
    "labels = []\n",
    "\n",
    "with open('../../data/clean/reddit_sentiments.csv', newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    has_header = csv.Sniffer().has_header(csvfile.read(1024))\n",
    "    csvfile.seek(0) \n",
    "    if has_header:\n",
    "        next(reader)  # just skip the header\n",
    "    for row in reader:\n",
    "        texts.append(row[0])\n",
    "        labels.append(row[1])\n",
    "\n",
    "print(\"texts:\", texts[0])\n",
    "print(\"labels:\", labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\zerok\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\zerok\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = {\n",
    "    'sentence': ['This film is good', 'This film is bad', 'This film is okay', 'This film is great'],\n",
    "    'sentiment': ['POS', 'NEG', 'NEU', 'POS']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment  sentence\n",
       "NEG        film        0.50\n",
       "           bad         0.50\n",
       "NEU        film        0.50\n",
       "           okay        0.50\n",
       "POS        film        0.50\n",
       "           good        0.25\n",
       "           great       0.25\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate prior probability\n",
    "prior_prob = df['sentiment'].value_counts(normalize=True)\n",
    "\n",
    "# calculate the probability of each word given the sentiment\n",
    "word_prob = df.groupby('sentiment').apply(lambda x: x['sentence'].apply(lambda y: [word.lower() for word in word_tokenize(y) if word.lower() not in stop_words]).explode().value_counts(normalize=True))\n",
    "\n",
    "word_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Emotion: POS\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def predict_sentiment(sentence):\n",
    "    words = [word.lower() for word in word_tokenize(sentence) if word.lower() not in stop_words]\n",
    "    posterior_prob = prior_prob.copy()\n",
    "    \n",
    "    for word in words:\n",
    "        for sentiment, prob in word_prob.items():\n",
    "            if word == sentiment[1]:\n",
    "                posterior_prob[sentiment[0]] *= prob\n",
    "    \n",
    "    posterior_prob /= posterior_prob.sum()\n",
    "    \n",
    "    return posterior_prob.idxmax()\n",
    "\n",
    "new_sentence = \"This film has excellent quality\"\n",
    "predicted_sentiment = predict_sentiment(new_sentence)\n",
    "print(f\"Predicted Emotion: {predicted_sentiment}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
