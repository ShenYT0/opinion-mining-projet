{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zerok\\miniconda3\\envs\\EI\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import defaultdict\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/datasets/beenakurian/reddit_comments_subreddit_canada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>well there are thousands of international stud...</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the article said dude needed a translator lol ...</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>for those convicted of crimes thats good</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good gotta bump up those rookie numbers</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6903</th>\n",
       "      <td>i like you big fan</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6904</th>\n",
       "      <td>sounds like date night around here frowning fa...</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6905</th>\n",
       "      <td>apparently the answer was yes</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6906</th>\n",
       "      <td>but with maaaaaassssksssss</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6907</th>\n",
       "      <td>omg hes writing like its an email lmao thats s...</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6908 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text sentiment\n",
       "0     well there are thousands of international stud...       NEG\n",
       "1     the article said dude needed a translator lol ...       NEG\n",
       "2              for those convicted of crimes thats good       POS\n",
       "3               good gotta bump up those rookie numbers       POS\n",
       "4                                                  good       POS\n",
       "...                                                 ...       ...\n",
       "6903                                 i like you big fan       POS\n",
       "6904  sounds like date night around here frowning fa...       POS\n",
       "6905                      apparently the answer was yes       NEU\n",
       "6906                         but with maaaaaassssksssss       NEU\n",
       "6907  omg hes writing like its an email lmao thats s...       POS\n",
       "\n",
       "[6908 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "datasetReddit = load_dataset(\"beenakurian/reddit_comments_subreddit_canada\", split='train')\n",
    "\n",
    "dfReddit = pd.DataFrame(datasetReddit)\n",
    "\n",
    "dfReddit.rename(columns={'comment': 'text'}, inplace=True)\n",
    "\n",
    "dfReddit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/datasets/stanfordnlp/imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>A hit at the time but now better categorised a...</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>I love this movie like no other. Another time ...</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>This film and it's sequel Barry Mckenzie holds...</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>'The Adventures Of Barry McKenzie' started lif...</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>The story centers around Barry McKenzie who mu...</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text sentiment\n",
       "0      I rented I AM CURIOUS-YELLOW from my video sto...       NEG\n",
       "1      \"I Am Curious: Yellow\" is a risible and preten...       NEG\n",
       "2      If only to avoid making this type of film in t...       NEG\n",
       "3      This film was probably inspired by Godard's Ma...       NEG\n",
       "4      Oh, brother...after hearing about this ridicul...       NEG\n",
       "...                                                  ...       ...\n",
       "24995  A hit at the time but now better categorised a...       POS\n",
       "24996  I love this movie like no other. Another time ...       POS\n",
       "24997  This film and it's sequel Barry Mckenzie holds...       POS\n",
       "24998  'The Adventures Of Barry McKenzie' started lif...       POS\n",
       "24999  The story centers around Barry McKenzie who mu...       POS\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetImdb = load_dataset(\"stanfordnlp/imdb\", split='train')\n",
    "\n",
    "dfImdb = pd.DataFrame(datasetImdb)\n",
    "\n",
    "dfImdb.rename(columns={'label': 'sentiment'}, inplace=True)\n",
    "\n",
    "dfImdb['sentiment'] = dfImdb['sentiment'].replace({0: 'NEG', 1: 'POS'})\n",
    "\n",
    "dfImdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>well there are thousands of international stud...</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the article said dude needed a translator lol ...</td>\n",
       "      <td>NEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>for those convicted of crimes thats good</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good gotta bump up those rookie numbers</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>A hit at the time but now better categorised a...</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>I love this movie like no other. Another time ...</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>This film and it's sequel Barry Mckenzie holds...</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>'The Adventures Of Barry McKenzie' started lif...</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>The story centers around Barry McKenzie who mu...</td>\n",
       "      <td>POS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31908 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text sentiment\n",
       "0      well there are thousands of international stud...       NEG\n",
       "1      the article said dude needed a translator lol ...       NEG\n",
       "2               for those convicted of crimes thats good       POS\n",
       "3                good gotta bump up those rookie numbers       POS\n",
       "4                                                   good       POS\n",
       "...                                                  ...       ...\n",
       "24995  A hit at the time but now better categorised a...       POS\n",
       "24996  I love this movie like no other. Another time ...       POS\n",
       "24997  This film and it's sequel Barry Mckenzie holds...       POS\n",
       "24998  'The Adventures Of Barry McKenzie' started lif...       POS\n",
       "24999  The story centers around Barry McKenzie who mu...       POS\n",
       "\n",
       "[31908 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([dfReddit, dfImdb])\n",
    "\n",
    "df.to_csv('../../data/raw/combined_data.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.sample(frac=0.8, random_state=42)\n",
    "test_df = df.drop(train_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the train and test data in files\n",
    "train_df.to_csv('../../data/clean/train.csv', index=False)\n",
    "test_df.to_csv('../../data/clean/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load 3 csv files\n",
    "train_df = pd.read_csv('../../data/clean/train.csv')\n",
    "test_df = pd.read_csv('../../data/clean/test.csv')\n",
    "df = pd.read_csv('../../data/raw/combined_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_data_by_sentiment(data, sentiment):\n",
    "    \"\"\"\n",
    "    Split the data DataFrame into separate lists based on sentiment.\n",
    "\n",
    "    Parameters:\n",
    "       data (DataFrame): The input DataFrame containing 'text' and 'sentiment' columns.\n",
    "       sentiment (str): The sentiment label to filter the data.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of text corresponding to the specified sentiment.\n",
    "    \"\"\"\n",
    "    return data[data['sentiment'] == sentiment]['text'].tolist()\n",
    "\n",
    "# Assuming df is your DataFrame containing 'text' and 'sentiment' columns\n",
    "positive_data = split_data_by_sentiment(df, 'POS')\n",
    "negative_data = split_data_by_sentiment(df, 'NEG')\n",
    "neutral_data = split_data_by_sentiment(df, 'NEU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 41\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m word_count\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Calculate word counts for textes with positive sentiment\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m word_count_positive \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_word_counts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msentiment\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPOS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Calculate word counts for textes with negative sentiment\u001b[39;00m\n\u001b[0;32m     44\u001b[0m word_count_negative \u001b[38;5;241m=\u001b[39m calculate_word_counts(train_df[train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEG\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[1;32mIn[10], line 30\u001b[0m, in \u001b[0;36mcalculate_word_counts\u001b[1;34m(textes)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Iterate through each text in the given list of textes\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m textes:\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m# Tokenize and preprocess the text using the preprocess_text function\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m# Iterate through each token in the preprocessed tokens\u001b[39;00m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m tokens:\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;66;03m# Increment the count for the current token in the word_count dictionary\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 15\u001b[0m, in \u001b[0;36mpreprocess_text\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     12\u001b[0m stemmer \u001b[38;5;241m=\u001b[39m PorterStemmer()\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Get a set of English stopwords from NLTK\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m stopwords_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[43mstopwords\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwords\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43menglish\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Apply stemming to each token and filter out stopwords\u001b[39;00m\n\u001b[0;32m     18\u001b[0m tokens \u001b[38;5;241m=\u001b[39m [stemmer\u001b[38;5;241m.\u001b[39mstem(token) \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m tokens \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m stopwords_set]\n",
      "File \u001b[1;32mc:\\Users\\zerok\\miniconda3\\envs\\EI\\lib\\site-packages\\nltk\\corpus\\reader\\wordlist.py:21\u001b[0m, in \u001b[0;36mWordListCorpusReader.words\u001b[1;34m(self, fileids, ignore_lines_startswith)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwords\u001b[39m(\u001b[38;5;28mself\u001b[39m, fileids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, ignore_lines_startswith\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m     20\u001b[0m         line\n\u001b[1;32m---> 21\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m line_tokenize(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileids\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line\u001b[38;5;241m.\u001b[39mstartswith(ignore_lines_startswith)\n\u001b[0;32m     23\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\zerok\\miniconda3\\envs\\EI\\lib\\site-packages\\nltk\\corpus\\reader\\api.py:218\u001b[0m, in \u001b[0;36mCorpusReader.raw\u001b[1;34m(self, fileids)\u001b[0m\n\u001b[0;32m    216\u001b[0m contents \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fileids:\n\u001b[1;32m--> 218\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[0;32m    219\u001b[0m         contents\u001b[38;5;241m.\u001b[39mappend(fp\u001b[38;5;241m.\u001b[39mread())\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m concat(contents)\n",
      "File \u001b[1;32mc:\\Users\\zerok\\miniconda3\\envs\\EI\\lib\\site-packages\\nltk\\corpus\\reader\\api.py:231\u001b[0m, in \u001b[0;36mCorpusReader.open\u001b[1;34m(self, file)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;124;03mReturn an open stream that can be used to read the given file.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;124;03mIf the file's encoding is not None, then the stream will\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;124;03m:param file: The file identifier of the file to read.\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    230\u001b[0m encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding(file)\n\u001b[1;32m--> 231\u001b[0m stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_root\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mopen(encoding)\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stream\n",
      "File \u001b[1;32mc:\\Users\\zerok\\miniconda3\\envs\\EI\\lib\\site-packages\\nltk\\data.py:334\u001b[0m, in \u001b[0;36mFileSystemPathPointer.join\u001b[1;34m(self, fileid)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjoin\u001b[39m(\u001b[38;5;28mself\u001b[39m, fileid):\n\u001b[0;32m    333\u001b[0m     _path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path, fileid)\n\u001b[1;32m--> 334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFileSystemPathPointer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\zerok\\miniconda3\\envs\\EI\\lib\\site-packages\\nltk\\compat.py:41\u001b[0m, in \u001b[0;36mpy3_data.<locals>._decorator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decorator\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     40\u001b[0m     args \u001b[38;5;241m=\u001b[39m (args[\u001b[38;5;241m0\u001b[39m], add_py3_data(args[\u001b[38;5;241m1\u001b[39m])) \u001b[38;5;241m+\u001b[39m args[\u001b[38;5;241m2\u001b[39m:]\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m init_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\zerok\\miniconda3\\envs\\EI\\lib\\site-packages\\nltk\\data.py:311\u001b[0m, in \u001b[0;36mFileSystemPathPointer.__init__\u001b[1;34m(self, _path)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;124;03mCreate a new path pointer for the given absolute path.\u001b[39;00m\n\u001b[0;32m    306\u001b[0m \n\u001b[0;32m    307\u001b[0m \u001b[38;5;124;03m:raise IOError: If the given path does not exist.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    310\u001b[0m _path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(_path)\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or directory: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m _path)\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path \u001b[38;5;241m=\u001b[39m _path\n",
      "File \u001b[1;32mc:\\Users\\zerok\\miniconda3\\envs\\EI\\lib\\genericpath.py:19\u001b[0m, in \u001b[0;36mexists\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 19\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert the text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation from the text using translation\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    \n",
    "    # Tokenize the text into individual words\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Initialize a Porter stemmer for word stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    # Get a set of English stopwords from NLTK\n",
    "    stopwords_set = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    # Apply stemming to each token and filter out stopwords\n",
    "    tokens = [stemmer.stem(token) for token in tokens if token not in stopwords_set]\n",
    "    \n",
    "    # Return the preprocessed tokens\n",
    "    return tokens\n",
    "\n",
    "def calculate_word_counts(textes):\n",
    "    # Initialize a defaultdict to store word counts, defaulting to 0 for unseen words\n",
    "    word_count = defaultdict(int)\n",
    "    \n",
    "    # Iterate through each text in the given list of textes\n",
    "    for text in textes:\n",
    "        # Tokenize and preprocess the text using the preprocess_text function\n",
    "        tokens = preprocess_text(text)\n",
    "        \n",
    "        # Iterate through each token in the preprocessed tokens\n",
    "        for token in tokens:\n",
    "            # Increment the count for the current token in the word_count dictionary\n",
    "            word_count[token] += 1\n",
    "    \n",
    "    # Return the word_count dictionary containing word frequencies\n",
    "    return word_count\n",
    "\n",
    "# Calculate word counts for textes with positive sentiment\n",
    "word_count_positive = calculate_word_counts(train_df[train_df['sentiment'] == 'POS']['text'])\n",
    "\n",
    "# Calculate word counts for textes with negative sentiment\n",
    "word_count_negative = calculate_word_counts(train_df[train_df['sentiment'] == 'NEG']['text'])\n",
    "\n",
    "# Calculate word counts for textes with neutral sentiment\n",
    "word_count_neutral = calculate_word_counts(train_df[train_df['sentiment'] == 'NEU']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save word counts to a pickle\n",
    "import pickle\n",
    "\n",
    "with open('../../src/model2/word_count_positive.pkl', 'wb') as f:\n",
    "    pickle.dump(word_count_positive, f)\n",
    "\n",
    "with open('../../src/model2/word_count_negative.pkl', 'wb') as f:\n",
    "    pickle.dump(word_count_negative, f)\n",
    "\n",
    "with open('../../src/model2/word_count_neutral.pkl', 'wb') as f:\n",
    "    pickle.dump(word_count_neutral, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load word counts from a pickle\n",
    "import pickle\n",
    "\n",
    "with open('../../src/model2/word_count_positive.pkl', 'rb') as f:\n",
    "    word_count_positive = pickle.load(f)\n",
    "\n",
    "with open('../../src/model2/word_count_negative.pkl', 'rb') as f:\n",
    "    word_count_negative = pickle.load(f)\n",
    "\n",
    "with open('../../src/model2/word_count_neutral.pkl', 'rb') as f:\n",
    "    word_count_neutral = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_likelihood(word_count, total_words, laplacian_smoothing=1):\n",
    "    # Create an empty dictionary to store the likelihood values\n",
    "    likelihood = {}\n",
    "    \n",
    "    # Get the number of unique words in the vocabulary\n",
    "    vocabulary_size = len(word_count)\n",
    "\n",
    "    # Iterate through each word and its corresponding count in the word_count dictionary\n",
    "    for word, count in word_count.items():\n",
    "        # Calculate the likelihood using Laplacian smoothing formula\n",
    "        # Laplacian smoothing is used to handle unseen words in training data\n",
    "        # The formula is (count + smoothing) / (total_words + smoothing * vocabulary_size)\n",
    "        likelihood[word] = (count + laplacian_smoothing) / (total_words + laplacian_smoothing * vocabulary_size)\n",
    "\n",
    "    # Return the calculated likelihood dictionary\n",
    "    return likelihood\n",
    "\n",
    "likelihood_positive = calculate_likelihood(word_count_positive, len(train_df[train_df['sentiment'] == 'POS']), 1)\n",
    "likelihood_negative = calculate_likelihood(word_count_negative, len(train_df[train_df['sentiment'] == 'NEG']), 1)\n",
    "likelihood_neutral = calculate_likelihood(word_count_neutral, len(train_df[train_df['sentiment'] == 'NEU']), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_log_prior(sentiment, data):\n",
    "    # Calculate the natural logarithm of the ratio of textes with the specified sentiment to the total number of textes\n",
    "    log_prior = math.log(len(data[data['sentiment'] == sentiment]) / len(data))\n",
    "    \n",
    "    # Return the calculated log prior\n",
    "    return log_prior\n",
    "\n",
    "# Calculate the log prior for textes with positive sentiment\n",
    "log_prior_positive = calculate_log_prior('POS', df)\n",
    "\n",
    "# Calculate the log prior for textes with negative sentiment\n",
    "log_prior_negative = calculate_log_prior('NEG', df)\n",
    "\n",
    "# Calculate the log prior for textes with neutral sentiment\n",
    "log_prior_neutral = calculate_log_prior('NEU', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of log-likelihood values for positive sentiment\n",
    "log_likelihood_positive = {word: math.log(prob) for word, prob in likelihood_positive.items()}\n",
    "\n",
    "# Create a dictionary of log-likelihood values for negative sentiment\n",
    "log_likelihood_negative = {word: math.log(prob) for word, prob in likelihood_negative.items()}\n",
    "\n",
    "# Create a dictionary of log-likelihood values for neutral sentiment\n",
    "log_likelihood_neutral = {word: math.log(prob) for word, prob in likelihood_neutral.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text_with_scores(text, log_likelihood_positive, log_likelihood_negative, log_likelihood_neutral,\n",
    "                               log_prior_positive, log_prior_negative, log_prior_neutral):\n",
    "    # Tokenize and preprocess the input text\n",
    "    tokens = preprocess_text(text)\n",
    "\n",
    "    # Calculate the log scores for each sentiment category\n",
    "    log_score_positive = log_prior_positive + sum([log_likelihood_positive.get(token, 0) for token in tokens])\n",
    "    log_score_negative = log_prior_negative + sum([log_likelihood_negative.get(token, 0) for token in tokens])\n",
    "    log_score_neutral = log_prior_neutral + sum([log_likelihood_neutral.get(token, 0) for token in tokens])\n",
    "\n",
    "    # Store the sentiment scores in a dictionary\n",
    "    sentiment_scores = {\n",
    "        'POS': log_score_positive,\n",
    "        'NEG': log_score_negative,\n",
    "        'NEU': log_score_neutral\n",
    "    }\n",
    "\n",
    "    # Determine the predicted sentiment based on the highest sentiment score\n",
    "    predicted_sentiment = max(sentiment_scores, key=sentiment_scores.get)\n",
    "    \n",
    "    # Return the predicted sentiment and the sentiment scores\n",
    "    return predicted_sentiment, sentiment_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sentence: I like this movie. It was fantastic and great. I would watch it again\n",
      "Predicted Sentiment: POS\n",
      "Sentiment Scores: {'POS': -16.903933911442426, 'NEG': -18.31958704092139, 'NEU': -33.149296155011136}\n"
     ]
    }
   ],
   "source": [
    "# Classify a sample text using the trained model\n",
    "text = \"I like this movie. It was fantastic and great. I would watch it again\"\n",
    "predicted_sentiment, sentiment_scores = classify_text_with_scores(text, log_likelihood_positive, log_likelihood_negative, log_likelihood_neutral,\n",
    "                                                                    log_prior_positive, log_prior_negative, log_prior_neutral)\n",
    "\n",
    "print(\"Sample sentence:\", text)\n",
    "print(\"Predicted Sentiment:\", predicted_sentiment)\n",
    "print(\"Sentiment Scores:\", sentiment_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 573.7555986313909\n",
      "Accuracy: 0.19357907253269918\n"
     ]
    }
   ],
   "source": [
    "# test the model and calculate the loss and the accuracy\n",
    "\n",
    "def test_model(data, log_likelihood_positive, log_likelihood_negative, log_likelihood_neutral,\n",
    "               log_prior_positive, log_prior_negative, log_prior_neutral):\n",
    "    # Initialize variables to store the total loss and the number of correct predictions\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    # Iterate through each text and its corresponding sentiment in the test data\n",
    "    for text, sentiment in zip(data['text'], data['sentiment']):\n",
    "        # Classify the text using the trained model\n",
    "        predicted_sentiment, sentiment_scores = classify_text_with_scores(text, log_likelihood_positive, log_likelihood_negative, log_likelihood_neutral,\n",
    "                                                                         log_prior_positive, log_prior_negative, log_prior_neutral)\n",
    "        \n",
    "        # Calculate the loss as the negative log likelihood of the true sentiment\n",
    "        loss = -sentiment_scores[sentiment]\n",
    "        \n",
    "        # Update the total loss with the calculated loss\n",
    "        total_loss += loss\n",
    "        \n",
    "        # Increment the number of correct predictions if the predicted sentiment matches the true sentiment\n",
    "        if predicted_sentiment == sentiment:\n",
    "            correct_predictions += 1\n",
    "    \n",
    "    # Calculate the average loss and the accuracy of the model\n",
    "    average_loss = total_loss / len(data)\n",
    "    accuracy = correct_predictions / len(data)\n",
    "    \n",
    "    # Return the average loss and accuracy\n",
    "    return average_loss, accuracy\n",
    "\n",
    "# Test the model using the test data\n",
    "average_loss, accuracy = test_model(test_df, log_likelihood_positive, log_likelihood_negative, log_likelihood_neutral,\n",
    "                                    log_prior_positive, log_prior_negative, log_prior_neutral)\n",
    "\n",
    "print(\"Average Loss:\", average_loss)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize a tokenizer with a maximum vocabulary size\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(train_df['text'])\n",
    "\n",
    "# Convert the text data to sequences of integers\n",
    "train_sequences = tokenizer.texts_to_sequences(train_df['text'])\n",
    "test_sequences = tokenizer.texts_to_sequences(test_df['text'])\n",
    "\n",
    "# Pad the sequences to ensure equal length input sequences\n",
    "train_padded = pad_sequences(train_sequences, padding='post', maxlen=100)\n",
    "test_padded = pad_sequences(test_sequences, padding='post', maxlen=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=5000, output_dim=64),\n",
    "    Bidirectional(LSTM(64)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compile the model with an Adam optimizer and categorical crossentropy loss\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a ModelCheckpoint callback to save the best model during training\n",
    "checkpoint = ModelCheckpoint('../../src/model1/lstm_model.keras', monitor='val_accuracy', save_best_only=True, save_weights_only=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m798/798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 157ms/step - accuracy: 0.5958 - loss: 0.7128 - val_accuracy: 0.8140 - val_loss: 0.4438\n",
      "Epoch 2/5\n",
      "\u001b[1m798/798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 141ms/step - accuracy: 0.8189 - loss: 0.4175 - val_accuracy: 0.8331 - val_loss: 0.3779\n",
      "Epoch 3/5\n",
      "\u001b[1m798/798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 142ms/step - accuracy: 0.8670 - loss: 0.3204 - val_accuracy: 0.8466 - val_loss: 0.3768\n",
      "Epoch 4/5\n",
      "\u001b[1m798/798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 145ms/step - accuracy: 0.9011 - loss: 0.2529 - val_accuracy: 0.8029 - val_loss: 0.4898\n",
      "Epoch 5/5\n",
      "\u001b[1m798/798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 155ms/step - accuracy: 0.9220 - loss: 0.2005 - val_accuracy: 0.8231 - val_loss: 0.5057\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the LSTM model on the training data\n",
    "history = model.fit(train_padded, tf.one_hot(train_df['sentiment'].map({'POS': 0, 'NEG': 1, 'NEU': 2}), depth=3),\n",
    "                    validation_data=(test_padded, tf.one_hot(test_df['sentiment'].map({'POS': 0, 'NEG': 1, 'NEU': 2}), depth=3)),\n",
    "                    epochs=5, batch_size=32, callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save the lstm model\n",
    "model.save('../../src/model1/lstm_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - accuracy: 0.8105 - loss: 0.5369\n",
      "Loss: 0.5057297348976135\n",
      "Accuracy: 0.8230677843093872\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(test_padded, tf.one_hot(test_df['sentiment'].map({'POS': 0, 'NEG': 1, 'NEU': 2}), depth=3))\n",
    "\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "Sample text: I like it. It was fantastic and great. I would watch it again\n",
      "Predicted sentiment: POS\n"
     ]
    }
   ],
   "source": [
    "# test lstm model with a sample text\n",
    "def predict_sentiment(text):\n",
    "    # Tokenize and pad the input text\n",
    "    sequence = tokenizer.texts_to_sequences([text])\n",
    "    padded_sequence = pad_sequences(sequence, padding='post', maxlen=100)\n",
    "    \n",
    "    # Predict the sentiment of the input text\n",
    "    prediction = model.predict(padded_sequence)\n",
    "    \n",
    "    # Get the predicted sentiment label\n",
    "    predicted_sentiment = ['POS', 'NEG', 'NEU'][tf.argmax(prediction, axis=1).numpy()[0]]\n",
    "    \n",
    "    # Return the predicted sentiment\n",
    "    return predicted_sentiment\n",
    "\n",
    "# Predict the sentiment of a sample text using the trained LSTM model\n",
    "text = \"I like it. It was fantastic and great. I would watch it again\"\n",
    "predicted_sentiment = predict_sentiment(text)\n",
    "\n",
    "print(\"Sample text:\", text)\n",
    "print(\"Predicted sentiment:\", predicted_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes - Correct Predictions: 34\n",
      "LSTM - Correct Predictions: 22\n",
      "Naive Bayes - Accuracy: 0.34\n",
      "LSTM - Accuracy: 0.22\n"
     ]
    }
   ],
   "source": [
    "# test comparison between the two models and create a chart to show the results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a list of sample texts to predict the sentiment\n",
    "sample_texts = test_df['text'].sample(100, random_state=42).tolist()\n",
    "\n",
    "# Predict the sentiment of each sample text using the Naive Bayes model\n",
    "predicted_sentiments_nb = [classify_text_with_scores(text, log_likelihood_positive, log_likelihood_negative, log_likelihood_neutral,\n",
    "                                                      log_prior_positive, log_prior_negative, log_prior_neutral)[0] for text in sample_texts]\n",
    "\n",
    "# Predict the sentiment of each sample text using the LSTM model\n",
    "predicted_sentiments_lstm = [predict_sentiment(text) for text in sample_texts]\n",
    "\n",
    "# Create a DataFrame to store the sample texts and their predicted sentiments\n",
    "comparison_df = pd.DataFrame({'text': sample_texts, 'Naive Bayes': predicted_sentiments_nb, 'LSTM': predicted_sentiments_lstm})\n",
    "\n",
    "# Calculate the number of correct predictions for each model\n",
    "correct_predictions_nb = (comparison_df['Naive Bayes'] == test_df.loc[comparison_df.index, 'sentiment']).sum()\n",
    "\n",
    "correct_predictions_lstm = (comparison_df['LSTM'] == test_df.loc[comparison_df.index, 'sentiment']).sum()\n",
    "\n",
    "# Create a bar chart to compare the number of correct predictions for each model\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "comparison_df['Naive Bayes'].value_counts().plot(kind='bar', color='skyblue', ax=ax, position=0, width=0.4, label='Naive Bayes')\n",
    "comparison_df['LSTM'].value_counts().plot(kind='bar', color='salmon', ax=ax, position=1, width=0.4, label='LSTM')\n",
    "\n",
    "ax.set_title('Comparison of Naive Bayes and LSTM Models')\n",
    "ax.set_xlabel('Sentiment')\n",
    "ax.set_ylabel('Number of Predictions')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n",
    "# save the chart\n",
    "fig.savefig('../plot/comparison_chart.png')\n",
    "\n",
    "# Print the number of correct predictions for each model\n",
    "print(\"Naive Bayes - Correct Predictions:\", correct_predictions_nb)\n",
    "print(\"LSTM - Correct Predictions:\", correct_predictions_lstm)\n",
    "\n",
    "# Print the accuracy of each model\n",
    "accuracy_nb = correct_predictions_nb / len(comparison_df)\n",
    "accuracy_lstm = correct_predictions_lstm / len(comparison_df)\n",
    "\n",
    "print(\"Naive Bayes - Accuracy:\", accuracy_nb)\n",
    "print(\"LSTM - Accuracy:\", accuracy_lstm)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
